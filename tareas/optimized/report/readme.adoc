= Reporte de optimizaciones
:experimental:
:nofooter:
:source-highlighter: pygments
:sectnums:
:stem: latexmath
:toc:
:xrefstyle: short



[[serial_optimizations]]
== Optimizaciones seriales

[%autowidth.stretch,options="header"]
|===
|Iter. |Etiqueta |Duración (s) |_Speedup_ |Descripción corta
|0 |Serial0 |4018.292573346 |1.00 |Versión serial inicial (Tarea01)
|1 |Serial1 |3638.373046516 |1.104420169 |Función configure_simulation
|2 | | | |
|===


[[serial_iter00]]
=== Versión serial original (Tarea01)

=== Aspectos no eficientes

* La copia de datos entre matrices en cada iteración. Esto es costoso porque se realiza un recorrido completo por la matriz, generando sobrecarga innecesaria, especialmente cuando se trabaja con matrices grandes.

* El bucle anidado en la actualización de celdas. Al igual que el aspecto anterior, a medida que el tamaño de la matriz aumenta, el costo de recorrer todas las celdas se vuelve más costoso.

* La condición de parada basada en max_delta. En cada iteración, el código verifica si la diferencia máxima entre las temperaturas actualizadas y las anteriores permite detener la simulación. Calcular esta diferencia implica comparar cada nueva temperatura con la anterior, lo que añade una operación adicional en cada celda.


=== Aspectos que se consideraron eficientes

* El uso de memoria dinámica para las matrices. El uso de malloc para asignar memoria para las matrices permite trabajar con láminas de tamaño arbitrario o desconocido.

* El uso de variables locales. Estas permiten accesar a ellas rápidamente, sin introducir dependencias innecesarias entre las iteraciones.


[[serial_iter01]]
=== Iteración 1

Se implementó la función configure_simulation, de forma que solamente se realiza un llamado a esta para gestionar la lectura de archivos, la simulación y la escritura de archivos. De esta forma, los distintos procesos no se realizan desde la función main, sino que se agiliza el manejo de datos a través de una sola función. La optimización sí logró mejorar el tiempo de ejecución.

=== Código sin la optimización (dentro de la función main)

    if (read_dimensions(filepath, &plate) != EXIT_SUCCESS) {
      fclose(file);
      return EXIT_FAILURE;
    }
    if (read_plate(filepath, &plate) != EXIT_SUCCESS) {
      fclose(file);
      return EXIT_FAILURE;
    }

    int k;
    time_t time_seconds;
    simulate(&plate, delta_t, alpha, h, epsilon, &k, &time_seconds);

    create_report(job_file, plate_filename, delta_t, alpha, h, epsilon, k,
      time_seconds);

    char output_filename[MAX_PATH_LENGTH];
    snprintf(output_filename, sizeof(output_filename), "plate%03d-%d.bin",
      atoi(&plate_filename[5]), k);
    write_plate(output_filename, &plate);


=== Código optimizado (dentro de la función main)

  for (uint64_t i = 0; i < struct_count; i++) {
    plate_filename = simulation_parameters[i].bin_name;
    /** Ejecutar la simulación. */
    configure_simulation(plate_filename, simulation_parameters[i], report_path,
      input_dir, output_dir);
  }



[[concurrent_optimizations]]
== Optimizaciones concurrentes

[%autowidth.stretch,options="header"]
|===
|Iter. |Etiqueta |Duración (s) |_Speedup_ |Eficiencia |Descripción corta
|- |Serial1 |3638.373046516 |1.00 |1.00 |Versión serial final
|- |Conc0 |4162.956732401 |0.873987716 | |Versión concurrente inicial (Tarea02)
|1 |Conc1 |3503.823419546 |1.188118302 | |Sincronización entre hilos
|2 |Conc2 |3239.175277653 | | |Mapeo dinámico
|===


[[conc_iter00]]
=== Versión concurrente inicial (Tarea02)

=== Aspectos no eficientes

* La asignación de memoria en cada hilo. Esto significa que si se usan muchos hilos, se deben crear múltiples copias de matrices grandes, aumentando el uso de memoria y el tiempo dedicado a la asignación y liberación de esta.

* La sincronización entre los hilos. Esta versión no cuenta con un mecanismo explícito de sincronización entre los hilos. Aunque cada hilo trabaja en una parte separada de la matriz, puede haber problemas en la lectura y escritura entre cada región.

* La distribución de las filas entre los hilos es estática. Esto puede ser un riesgo debido a que, si algunas filas tienen más celdas a actualizar debido a su proximidad con otras regiones, los hilos podrían estar desbalanceados en su carga.


=== Aspectos que se consideraron eficientes

* La modularización del código. Se utilizaron las funciones configure_simulation, simulate y thread_sim, para facilitar la separación entre las tareas de configuración, simulación principal y el trabajo que realiza cada hilo, permitiendo realizar cambios o mejoras de manera localizada sin afectar todo el código.

* El manejo de los parámetros de la simulación. Estos se organizaron en una estructura de datos compartida, lo que simplifica el acceso a ellos por parte de los hilos. De esta forma, se reduce la necesidad de pasos adicionales para pasar múltiples argumentos a las funciones.


[[conc_iter01]]
=== Iteración 1

La optimización se centra en el uso de un mutex para sincronizar el acceso a la matriz compartida durante la simulación. Esto permitie evitar condiciones de carrera, donde dos o más hilos intenten leer o escribir en las mismas celdas simultáneamente. De esta forma, el programa es capaz de sincronizar los hilos para realizar trabajo paralelo sobre la matriz sin interferir entre ellos, evitando errores que puedan surgir en las simulaciones más complejas. La optimización sí logró mejorar el tiempo de ejecución.

=== Código sin la optimización (dentro de la función configure_simulation)

    uint64_t num_states;
    num_states = simulate(shared_data, thread_count);
    sim_states[i] = num_states;


=== Código optimizado (dentro de la función configure_simulation)

  pthread_mutex_init(&shared_data->matrix_mutex, NULL);

  /** Iniciar la simulación. */
  uint64_t states = 0;
  simulate(&states, thread_count, shared_data);

  /** Destruir el mutex. */
  pthread_mutex_destroy(&shared_data->matrix_mutex);


[[conc_iter02]]
=== Iteración 2

El uso de mapeo dinámico en lugar de mapeo estático permite una mejor distribución de la carga de trabajo entre los hilos. Al tener una distribución más equilibrada de la carga, los hilos que terminan su trabajo pueden continuar trabajando en nuevas filas mientras otros siguen procesando su parte. Esto mejora el rendimiento general, ya que se logra un uso más eficiente de los hilos a lo largo de toda la simulación. La optimización sí logró mejorar el tiempo de ejecución.

=== Código sin la optimización (dentro de la función simulate)

      uint64_t rows_per_thread = (shared_data->rows - 2) / thread_count;
      thread_data[i].start_row = 1 + i * rows_per_thread;
      if (i == thread_count - 1) {
        thread_data[i].end_row = shared_data->rows - 1;
      } else {
        thread_data[i].end_row = thread_data[i].start_row + rows_per_thread;
      }
      thread_data[i].shared_data = shared_data;


=== Código optimizado (dentro de la función simulate)

      uint64_t rows_per_thread = (shared_data->rows - 2) / thread_count;
      thread_data[i].start_row = 1 + i * rows_per_thread;
      thread_data[i].end_row = (i == thread_count - 1) ?
        shared_data->rows - 1 : thread_data[i].start_row + rows_per_thread;
      thread_data[i].shared_data = shared_data;


[[optimization_comparison]]
=== Comparación de optimizaciones

(pendiente)


[[concurrency_comparison]]
=== Comparación del grado de concurrencia

(pendiente)
